{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 40,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 4, 48]) # patch.shape\n",
      "torch.Size([1, 4, 8]) # patch_embedding.shape\n"
     ]
    }
   ],
   "source": [
    "import torch.nn.functional as F\n",
    "import torch as t\n",
    "import torch.nn as nn\n",
    "\n",
    "def image2emb_naive(image, patch_size, weight):\n",
    "    \"\"\"\n",
    "    image shape: [bs,c,h,w]\n",
    "    weight: DNN weight\n",
    "    \"\"\"\n",
    "    patch = F.unfold(image, kernel_size=patch_size, stride=patch_size).transpose(-1, -2)\n",
    "    patch_embedding = patch @ weight\n",
    "\n",
    "    print(patch.shape, \"# patch.shape\")\n",
    "    print(patch_embedding.shape, \"# patch_embedding.shape\")\n",
    "\n",
    "    return patch_embedding\n",
    "\n",
    "\n",
    "def test_image2emb_naive():\n",
    "    bs, ic, ih, iw = 1, 3, 8, 8\n",
    "    patch_size = 4\n",
    "    model_dim = 8\n",
    "    patch_depth = patch_size * patch_size * ic\n",
    "    image = t.randn(bs, ic, ih, iw)\n",
    "    weight = t.randn(patch_depth, model_dim)\n",
    "    image2emb_naive(image, patch_size, weight)\n",
    "\n",
    "\n",
    "test_image2emb_naive()\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def image2emb_conv(image, kernel, stride):\n",
    "    # conv_output: [bs, oc, oh, ow]\n",
    "    conv_output = F.conv2d(image, kernel, stride=stride)\n",
    "    bs, oc, oh, ow = conv_output.shape\n",
    "    embedding = conv_output.reshape((bs, oc, oh*ow)).transpose(-1, -2)\n",
    "    return embedding\n",
    "\n",
    "\n",
    "def test_image2emb_conv():\n",
    "    bs, ic, ih, iw = 1, 3, 8, 8\n",
    "    patch_size = 4\n",
    "    model_dim = 8\n",
    "    image = t.randn(bs, ic, ih, iw)\n",
    "    kernel = t.randn(model_dim, ic, patch_size, patch_size)\n",
    "    patch_embedding = image2emb_conv(image, kernel, stride=patch_size)\n",
    "    print(patch_embedding.shape)\n",
    "    return patch_embedding\n",
    "\n",
    "test_image2emb_conv()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(2.7252, grad_fn=<NllLossBackward0>)\n"
     ]
    }
   ],
   "source": [
    "def append_cls_token(patch_embedding):\n",
    "    bs, _, model_dim = patch_embedding.shape\n",
    "    cls_token_embedding = t.randn(bs, 1, model_dim, requires_grad=True)\n",
    "    # 把cls放到第一个位置上\n",
    "    token_embedding = t.cat([cls_token_embedding, patch_embedding], dim=1)\n",
    "    return token_embedding\n",
    "\n",
    "\n",
    "def append_position_embedding(max_num_token, token_embedding):\n",
    "    \"\"\"\n",
    "    max_num_token:序列最大长度\n",
    "    \"\"\"\n",
    "    bs, seq_len, model_dim = token_embedding.shape\n",
    "    # shape = [vocab_size, model_dim]\n",
    "    position_embedding_table = t.randn(max_num_token, model_dim, requires_grad=True)\n",
    "    position_embedding = t.tile(position_embedding_table[:seq_len], [bs, 1, 1])\n",
    "    token_embedding += position_embedding\n",
    "    return token_embedding\n",
    "\n",
    "\n",
    "def pass_embedding_to_encoder(token_embedding):\n",
    "    bs, seq_len, model_dim = token_embedding.shape\n",
    "    encoder_layer = nn.TransformerEncoderLayer(d_model=model_dim, nhead=8)\n",
    "    encoder = nn.TransformerEncoder(encoder_layer, num_layers=6)\n",
    "    encoder_output = encoder(token_embedding)\n",
    "    return encoder_output\n",
    "\n",
    "\n",
    "def do_classification(encoder_output, num_class, model_dim, label):\n",
    "    # label = t.randint(10,(bs,))\n",
    "    cls_token_output = encoder_output[:, 0, :]\n",
    "    linear_layer = nn.Linear(model_dim, num_class)\n",
    "    logits = linear_layer(cls_token_output)\n",
    "    loss_fn = nn.CrossEntropyLoss()\n",
    "    loss = loss_fn(logits, label)\n",
    "    return loss\n",
    "\n",
    "def test_full():\n",
    "    bs, ic, ih, iw = 1, 3, 8, 8\n",
    "    patch_size = 4\n",
    "    model_dim = 8\n",
    "    max_num_token = 16\n",
    "    num_class = 10\n",
    "    label = t.randint(10,(bs,))\n",
    "    image = t.randn(bs, ic, ih, iw)\n",
    "    kernel = t.randn(model_dim, ic, patch_size, patch_size)\n",
    "    patch_embedding = image2emb_conv(image, kernel, stride=patch_size)\n",
    "    token_embedding = append_position_embedding(max_num_token ,append_cls_token(patch_embedding))\n",
    "    encoder_output = pass_embedding_to_encoder(token_embedding)\n",
    "    loss = do_classification(encoder_output, num_class, model_dim, label)\n",
    "    print(loss)\n",
    "\n",
    "\n",
    "test_full()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}